# -*- coding: utf-8 -*-
"""Air-Quality-Index-Prediction complete.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q_UCZZyxsd0ZxKM17vGzN8YT8bM1YtDc

### Problem Statement




#####  Air pollution is among the most serious environmental problems with adverse effects on public health and the climate. The Air Quality Index (AQI) is a normalized measure of the evaluation of air quality. However, traditional AQI monitoring networks rely on expensive fixed-point sensors covering a limited number of sites. The aim of this project is to develop a machine learning model for AQI prediction based on leading pollutants such as PM2.5, PM10, NO2, SO2, CO, and O3. The goal is to develop a predictive model to predict AQI from real-time pollutant concentrations and implement the model as a web application for better accessibility.

##  AQI Prediction Model using Python
 ###  PM2.5 PM10
 ###  NO, NO2
 ###  NH3 - Ammonia
 ###  CO
 ###  So2
 ###  O3
 ###  Benzene, Toluene, Xylene
"""

pip install numpy pandas matplotlib seaborn scikit-learn streamlit

pip list

# importing necessaries libraries

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from warnings import filterwarnings
filterwarnings('default')

# Load Dataset
df = pd.read_csv(r'air quality data.csv')
df

#first 5 rows
df.head()

df.info()

df.describe()

df.duplicated()

# null values
df.isnull()

#complete null values
df.isnull().sum()

# Drop rows where AQI is missing
df.dropna(subset=['AQI'], inplace=True)

# arranging null values in order
df.isnull().sum().sort_values(ascending=False)

#shape of dataset
df.shape

df.info()

#stats of the dataset
df.describe()

df.describe().T

#percentage ofnull values in dataset
null_values_percentages=(df.isnull().sum()/df.isnull().count()*100).sort_values(ascending=False)
null_values_percentages

""" ## key considerations
   ### Xylene has the highest percentage of missing values - 61.86%
   ### PM10 and NH3 28 - 26 %
"""

pip install PyQt6

"""### week 2 - visualization"""

# Commented out IPython magic to ensure Python compatibility.
# Univariate analysis
import matplotlib
# %matplotlib inline
df['Xylene'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['PM10'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['NH3'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['Benzene'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['Toluene'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['NOx'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['O3'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['CO'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['PM2.5'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['SO2'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

df['AQI'].plot(kind = 'hist', figsize=(10,5))
plt.legend()
plt.show()

# Distribution of AQi from 2015 to 2020
sns.displot(df, x='AQI', color='green')
plt.show()

# Bivariate
sns.set_theme(style="darkgrid",color_codes='b')
graph = sns.catplot(x="City", kind='count', data=df, height=5, aspect=3)
graph.set_xticklabels(rotation=90)

# Bivariate
sns.set_theme(style="darkgrid",color_codes='r')
graph = sns.catplot(x="City", kind='count', data=df, height=5, aspect=3,palette="viridis")
graph.set_xticklabels(rotation=90)

sns.set_theme(style="darkgrid")
graph = sns.catplot(x="City", kind='count', data=df, col="AQI_Bucket", col_wrap=2,
                    height=3.5, aspect=3)
graph.set_xticklabels(rotation=90)

graph1 = sns.catplot(x='City', y='PM2.5', kind='box', data=df, height=5, aspect=3)
graph1.set_xticklabels(rotation=90)

graph2 = sns.catplot(x='City', y='NO2', kind='box', data=df, height=5, aspect=3)
graph2.set_xticklabels(rotation=90)

graph3 = sns.catplot(x='City', y='O3', kind='box', data=df, height=5, aspect=3)
graph3.set_xticklabels(rotation=90)

graph4 = sns.catplot(x='City', y='SO2', kind='box', data=df, height=5, aspect=3)
graph4.set_xticklabels(rotation=90)

graph5 = sns.catplot(x='AQI_Bucket', data=df, kind='count', height=6, aspect=3)
graph5.set_xticklabels(rotation=90)

# check the null values
df.isnull().sum().sort_values(ascending=False)

df.describe().loc['mean']

df = df.replace({
    "PM2.5":{np.nan:67.476613},
    "PM10":{np.nan:118.454435},
    "NO": {np.nan:17.622421},
    "NO2": {np.nan:28.978391},
    "NOx": {np.nan:32.289012},
    "NH3": {np.nan:23.848366},
    "CO":  {np.nan:2.345267},
    "SO2": {np.nan:34.912885},
    "O3": {np.nan:38.320547},
    "Benzene": {np.nan:3.458668},
    "Toluene": {np.nan:9.525714},
    "Xylene": {np.nan:3.588683}
})

fill_values = {
    "PM2.5": 67.476613,
    "PM10": 118.454435,
    "NO": 17.622421,
    "NO2": 28.978391,
    "NOx": 32.289012,
    "NH3": 23.848366,
    "CO": 2.345267,
    "SO2": 34.912885,
    "O3": 38.320547,
    "Benzene": 3.458668,
    "Toluene": 9.525714,
    "Xylene": 3.588683
}

df = df.fillna(fill_values)

df.head()

# otherwise
df = df.replace({
    "PM2.5":{np.nan:67.476613},
    "PM10":{np.nan:118.454435},
    "NO": {np.nan:17.622421},
    "NO2": {np.nan:28.978391},
    "NOx": {np.nan:32.289012},
    "NH3": {np.nan:23.848366},
    "CO":  {np.nan:2.345267},
    "SO2": {np.nan:34.912885},
    "O3": {np.nan:38.320547},
    "Benzene": {np.nan:3.458668},
    "Toluene": {np.nan:9.525714},
    "Xylene": {np.nan:3.588683}
})

df.isnull().sum()

df = df.drop(['AQI_Bucket'], axis=1)
df.head()

sns.boxplot(data=df[['PM2.5', 'PM10']])

sns.boxplot(data=df[['NO', 'NO2', 'NOx', 'NH3']])

sns.boxplot(data=df[['O3', 'SO2']])

# IQR Method - Q3 Q1
#q3(third percentile)->(0.25)
#q1(first percentile)->(0.75)
#IQR=q3-q1
def replace_outliers(df):
    for column in df.select_dtypes(include=['number']).columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lb = Q1 - 1.5 * IQR
        ub = Q3 + 1.5 * IQR
        df[column] = df[column].apply(
            lambda x: Q1 if x < lb else (Q3 if x > ub else x)
        )
    return df

df = replace_outliers(df)
df

df.describe()

df.describe().T

sns.boxplot(data=df[['PM2.5', 'PM10']])

sns.boxplot(data=df[['O3', 'SO2']])

sns.displot(df, x='AQI', color='blue')
plt.show()

df1 = df.drop(columns=['City'])

# Multivariate Analysis - Heatmap
#exclude non-numeric columns
df1_numeric = df1.select_dtypes(include=['number'])
# correlation matrix for numeric columns only
corr_matrix = df1_numeric.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='Pastel1')
plt.show()

# Multivariate Analysis - Heatmap
#exclude non-numeric columns
df1_numeric = df1.select_dtypes(include=['number'])
# correlation matrix for numeric columns only
corr_matrix = df1_numeric.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.show()

#week 3 data modeling

df.drop(['Date', 'City'], axis = 1, inplace=True)
df.head()

df.columns

# Scaling - Standard Scaler
from sklearn.preprocessing import StandardScaler
df1 = StandardScaler().fit_transform(df)
df1

df = pd.DataFrame(df1, columns=df.columns)
df.head()

# Feature & Target Selection
X = df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3',
       'Benzene', 'Toluene', 'Xylene']]
y = df['AQI']

X.head()

# Split the data into training and testing data - Training set - 80% | Testing set - 20%
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print('Shape of X Train',X_train.shape)
print('Shape of X Test',X_test.shape)
print('Shape of y Train',y_train.shape)
print('Shape of y Test',y_test.shape)

df.columns

# Feature & Target Selection
X = df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3',
       'Benzene', 'Toluene', 'Xylene']]
y = df['AQI']

X.head()

from sklearn.metrics import mean_squared_error, r2_score

from sklearn.linear_model import LinearRegression
# Linear Regression Model
LR = LinearRegression()
LR.fit(X_train, y_train)

# Predicting the values:
train_pred = LR.predict(X_train) # Predicting train
test_pred = LR.predict(X_test) # Predicting test

# Evaluation for Linear Regression
RMSE_train = np.sqrt(mean_squared_error(y_train, train_pred))
RMSE_test = np.sqrt(mean_squared_error(y_test, test_pred))

print('RMSE Train Data =', str(RMSE_train))
print('RMSE Test Data =', str(RMSE_test))
print('_' * 60)
print('R Squared value for Train =', LR.score(X_train, y_train))
print('R Squared value on Test =', LR.score(X_test, y_test))

from sklearn.neighbors import KNeighborsRegressor
# KNN
knn = KNeighborsRegressor()
knn.fit(X_train, y_train)

# Predicting the values:
train_pred = knn.predict(X_train) # Predicting train
test_pred = knn.predict(X_test) # Predicting test

# Evaluation for KNN
RMSE_train = (np.sqrt(mean_squared_error(y_train, train_pred)))
RMSE_test = (np.sqrt(mean_squared_error(y_test, test_pred)))
print('RMSE Train Data = ', str(RMSE_train))
print('RMSE Test Data = ', str(RMSE_test))
print('_'* 60)
print('R Squared value for Train = ', knn.score(X_train, y_train))
print('R Squared value on Test = ', knn.score(X_test, y_test))

# Decision Tree
from sklearn.tree import DecisionTreeRegressor
dtr = DecisionTreeRegressor()
dtr.fit(X_train, y_train)

# Predicting the values:
train_pred = dtr.predict(X_train) # Predicting train
test_pred = dtr.predict(X_test) # Predicting test

# Evaluation for Decision Tree Regressor
RMSE_train = (np.sqrt(mean_squared_error(y_train, train_pred)))
RMSE_test = (np.sqrt(mean_squared_error(y_test, test_pred)))
print('RMSE Train Data = ', str(RMSE_train))
print('RMSE Test Data = ', str(RMSE_test))
print('--'* 60)
print('R Squared value for Train = ', dtr.score(X_train, y_train))
print('R Squared value on Test = ', dtr.score(X_test, y_test))

from sklearn.ensemble import RandomForestRegressor
# Random   Regressor
rfr = RandomForestRegressor()
rfr.fit(X_train, y_train)

# Predicting the values:
train_pred = rfr.predict(X_train) # Predicting train
test_pred = rfr.predict(X_test) # Predicting test

# Evaluation for Randome Forest Regressor
RMSE_train = (np.sqrt(mean_squared_error(y_train, train_pred)))
RMSE_test = (np.sqrt(mean_squared_error(y_test, test_pred)))
print('RMSE Train Data = ', str(RMSE_train))
print('RMSE Test Data = ', str(RMSE_test))
print('_'* 60)
print('R Squared value for Train = ', rfr.score(X_train, y_train))
print('R Squared value on Test = ', rfr.score(X_test, y_test))

import pickle as pkl
# Save the trained model as a pickle file
with open("aqi_model.pkl", "wb") as model_file:
    pickle.dump(rfr, model_file)

print("✅ Model saved as 'aqi_model.pkl'")

import os
import streamlit as st
import numpy as np
import pickle
import matplotlib.pyplot as plt

# Load the trained machine learning model from the 'pkl' directory
model_path = "pkl/aqi_model.pkl"
if os.path.exists(model_path):
    with open(model_path, "rb") as model_file:
        model = pickle.load(model_file)
else:
    model = None

from sklearn.model_selection import GridSearchCV

# Hyperparameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Grid Search
grid_search = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Best parameters
print("Best parameters found: ", grid_search.best_params_)

# Best estimator
best_rfr = grid_search.best_estimator_

# Evaluation
train_pred = best_rfr.predict(X_train)
test_pred = best_rfr.predict(X_test)
RMSE_train = np.sqrt(mean_squared_error(y_train, train_pred))
RMSE_test = np.sqrt(mean_squared_error(y_test, test_pred))
print('Best RMSE Train Data =', str(RMSE_train))
print('Best RMSE Test Data =', str(RMSE_test))
print('Best R Squared value for Train =', best_rfr.score(X_train, y_train))
print('Best R Squared value on Test =', best_rfr.score(X_test, y_test))

from sklearn.model_selection import GridSearchCV

# Hyperparameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
c
# Grid Search
grid_search = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=2, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)
# Best estimator
best_rfr = grid_search.best_estimator_
# Evaluation
train_pred = best_rfr.predict(X_train)
test_pred = best_rfr.predict(X_test)
RMSE_train = np.sqrt(mean_squared_error(y_train, train_pred))
RMSE_test = np.sqrt(mean_squared_error(y_test, test_pred))
print('Best RMSE Train Data =', str(RMSE_train))
print('Best RMSE Test Data =', str(RMSE_test))
print('Best R Squared value for Train =', best_rfr.score(X_train, y_train))
print('Best R Squared value on Test =', best_rfr.score(X_test, y_test))

# Importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from warnings import filterwarnings
filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

# Load and preprocess your dataset
df = pd.read_csv('air quality data.csv')
# All preprocessing steps here

# Feature & Target Selection
X = df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene']]
y = df['AQI']

# Split the data into training and testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Linear Regression Model
models = {
    "Linear Regression": LinearRegression(),
    "K-Nearest Neighbors": KNeighborsRegressor(),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Support Vector Regressor": SVR(),
    "Gradient Boosting Regressor": GradientBoostingRegressor()
}

# Evaluate each model
for model_name, model in models.items():
    model.fit(X_train, y_train)
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)
    RMSE_train = np.sqrt(mean_squared_error(y_train, train_pred))
    RMSE_test = np.sqrt(mean_squared_error(y_test, test_pred))
    r2_train = r2_score(y_train, train_pred)
    r2_test = r2_score(y_test, test_pred)

    print(f'{model_name}:')
    print(f'  RMSE Train Data = {RMSE_train}')
    print(f'  RMSE Test Data = {RMSE_test}')
    print(f'  R Squared value for Train = {r2_train}')
    print(f'  R Squared value on Test = {r2_test}')
    print('_' * 60)

# streamlit
#app
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

# Load and preprocess the dataset
df = pd.read_csv('air quality data.csv')
# Preprocessing steps (same as your previous code)
# ...

# Feature & Target Selection
X = df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'Xylene']]
y = df['AQI']

# Split the data into training and testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the models
models = {
    "Linear Regression": LinearRegression(),
    "K-Nearest Neighbors": KNeighborsRegressor(),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Support Vector Regressor": SVR(),
    "Gradient Boosting Regressor": GradientBoostingRegressor()
}

# Streamlit application
st.title("AQI Prediction Model")

# Sidebar for selecting the model
model_name = st.sidebar.selectbox("Select Model", list(models.keys()))

# Fit and evaluate the selected model
model = models[model_name]
model.fit(X_train, y_train)
train_pred = model.predict(X_train)
test_pred = model.predict(X_test)
RMSE_train = np.sqrt(mean_squared_error(y_train, train_pred))
RMSE_test = np.sqrt(mean_squared_error(y_test, test_pred))
r2_train = r2_score(y_train, train_pred)
r2_test = r2_score(y_test, test_pred)

# Display results
st.write(f"## {model_name} Results")
st.write(f"### RMSE Train Data: {RMSE_train}")
st.write(f"### RMSE Test Data: {RMSE_test}")
st.write(f"### R Squared value for Train: {r2_train}")
st.write(f"### R Squared value on Test: {r2_test}")

# Option to view dataset
if st.checkbox('Show dataset'):
    st.write(df)

# Visualizations
st.write("## Data Distribution")
st.write(sns.displot(df, x='AQI', color='red'))
st.pyplot()